import os
import json
import numpy as np
import torch
import torch.nn.functional as F
from tqdm import tqdm
from functools import partial
from multiprocessing import Pool

from mri_ct_diffusion.config import ORIGINAL_DATA_ROOT, PREPROCESS_NUM_WORKERS, PREPROCESSED_DATA_ROOT, RESIZE_INTERPOLATE_MODE, TARGET_SIZE
from mri_ct_diffusion.preprocessing.utils import get_patient_ids, load_patient_volumes
from mri_ct_diffusion.preprocessing.ct import preprocess_ct
from mri_ct_diffusion.preprocessing.mr import preprocess_mr
from mri_ct_diffusion.preprocessing.stats import load_global_stats

#stats = load_global_stats() ## TODO: Update per region
#ct_min, ct_max = stats["ct_min"], stats["ct_max"]
#mr_max = stats["mr_max"]

def resize_volume(volume: np.ndarray) -> np.ndarray:
    #¬†removed resizing as not needed for now
    tensor = torch.from_numpy(volume)
    return tensor

def normalize_01(t: torch.Tensor) -> torch.Tensor:
  """Normalizes a tensor to the [0, 1] range."""
  return (t - t.min()) / (t.max() - t.min())

def normalize_11(t: torch.Tensor) -> torch.Tensor:
    return normalize_01(t) * 2 - 1

def quantile_filer(x: torch.Tensor, min_q=0.01, max_q=0.99):
    lower_bound = torch.quantile(x, min_q)
    upper_bound = torch.quantile(x, max_q)
    mask = (x >= lower_bound) & (x <= upper_bound)
    x_masked = x[mask]
    assert x_masked.numel() == x.numel(), "Quantile filtering did not preserve the number of elements"
    return x_masked

def abs_filter(x: torch.Tensor, min_val=-2.2, max_val=2.2):
    mask = (x >= min_val) & (x <= max_val)
    x_masked = x[mask]
    assert x_masked.numel() == x.numel(), "Absolute value filtering did not preserve the number of elements"
    return x_masked

def normalize_to_range(tensor: torch.Tensor, range_min: float, range_max: float) -> torch.Tensor:
  # Ensure the range values are floats to guarantee float division
  range_min = float(range_min)
  range_max = float(range_max)

  # Calculate the span of the custom input range
  span = range_max - range_min
  normalized_tensor = (tensor - range_min) / span
  return normalized_tensor

def process_patient(patient_id, root_dir):
    pid = patient_id
    try:
        ct, mr, _ = load_patient_volumes(root_dir, pid)
        ct = np.zeros_like(mr)
        if ct is None or mr is None:
            return (pid, False, "Missing CT or MR file")
        #print(f"Patient volume loaded {pid}")

        #Preprocess
        # ct_processed = preprocess_ct(ct, mask=mask, ct_min=ct_min, ct_max=ct_max) ## TODO: switch to percentile variable values...
        # print(f"CT processed {pid}")
        # mr_processed = preprocess_mr(mr, mask=mask, mr_max=mr_max, apply_n4=False) ## TODO: switch to percentile variable values...
        # print(f"MR processed {pid}")
        #¬†SKIPPING PREPROCESSING FOR NOW AS WE USE LATENT VOLUMES
        ct_processed = ct
        mr_processed = mr
        
        #Resize
        ct_processed = resize_volume(ct_processed)
        mr_processed = resize_volume(mr_processed)
        #print(f"MR and CT resized {pid}")
        ct_processed = torch.clamp(ct_processed, -2, 2)
        mr_processed = torch.clamp(mr_processed, -2, 2)
        # ct_processed = quantile_filer(ct_processed)
        # mr_processed = quantile_filer(mr_processed)
        # ct_processed = abs_filter(ct_processed)
        # mr_processed = abs_filter(mr_processed)

        # #normalizing tensors 
        # ct_processed = normalize_01(ct_processed)
        # mr_processed = normalize_01(mr_processed)
        # normalization commented out, since it seems to result in worse results
        ct_processed = normalize_11(ct_processed)
        mr_processed = normalize_11(mr_processed)
        # print(f'CT MIN/MAX: {ct_processed.min()}, {ct_processed.max()}')
        # print(f'MR MIN/MAX: {mr_processed.min()}, {mr_processed.max()}')
        

        #¬†skipping mask and skipped slices as does not apply to latents
        #Identify and remove black (empty) slices
        # valid_mask = np.any(mr_processed != 0, axis=(1, 2))
        # num_total_slices = len(mr_processed)
        # num_black_slices = np.sum(~valid_mask)
        # num_valid_slices = np.sum(valid_mask)

        # black_slice_indices = [int(i) for i, is_valid in enumerate(valid_mask) if not is_valid]

        # ct_processed = ct_processed[valid_mask]
        # mr_processed = mr_processed[valid_mask]
        # print(f"Black slices out {pid}")

        # if num_valid_slices == 0:
        #     return (pid, False, "No valid slices")

        #Save preprocessed 
        output_path = os.path.join(PREPROCESSED_DATA_ROOT)
        os.makedirs(output_path, exist_ok=True)
        np.save(os.path.join(output_path, f"{pid}_latent_mr.npy"), mr_processed.to(torch.float32).numpy())
        np.save(os.path.join(output_path, f"{pid}_latent_ct.npy"), ct_processed.to(torch.float32).numpy())
        
        #print(f"Proprocessed saved! {pid}")

        # # Save black slice indices for reinsertion during inference
        # with open(os.path.join(output_path, "meta.json"), "w") as f:
        #     json.dump({"black_slice_indices": black_slice_indices}, f)

        return (pid, True, f"Processed {len(mr_processed)} slices, saved to {output_path}")

    except Exception as e:
        print(f"Error processing patient {pid}: {e}")
        return (pid, False, str(e))


def main():
    os.makedirs(PREPROCESSED_DATA_ROOT, exist_ok=True)
    patient_ids = get_patient_ids(ORIGINAL_DATA_ROOT)
    print(f"‚öôÔ∏è Launching preprocessing on {len(patient_ids)} patients using {PREPROCESS_NUM_WORKERS} workers...")

    process_func = partial(process_patient, root_dir=ORIGINAL_DATA_ROOT)
    with Pool(processes=PREPROCESS_NUM_WORKERS) as pool:
        results = list(tqdm(pool.imap(process_func, patient_ids), total=len(patient_ids)))

    saved = [r for r in results if r[1]]
    failed = [r for r in results if not r[1]]

    print("\n‚úÖ Preprocessing complete.")
    print(f"‚úÖ Saved: {len(saved)} patients to: {PREPROCESSED_DATA_ROOT}")
    # if saved:
    #     print("\nüîç Slice Stats:")
    #     for pid, _, msg in saved:
    #         print(f"   - {pid}: {msg}")

    if failed:
        print(f"\n‚ö†Ô∏è Skipped: {len(failed)} patients")
        for pid, _, reason in failed:
            print(f"   - {pid}: {reason}")


if __name__ == "__main__":
    main()
