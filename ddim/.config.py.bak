import os
import torch

## Define key directories which will be used for data retrieval and output storage
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_DIR    = os.path.join(BASE_DIR, '../output_latent_ct')
ORIGINAL_DATA_ROOT     = os.path.join('/workspace/latent-val/')
FULL_SET_DATA_ROOT     = os.path.join('/workspace/latent-val/')
PREPROCESSED_DATA_ROOT = os.path.join(BASE_DIR, "../preprocessed")

## Image parameters
IMAGE_SIZE = 128 # assuming latent images are 128x128, ergo input to MAISI is 512x512
IMAGE_CHANNELS = 4 # 4 set for compatibility with latent volumes from MAISI
TARGET_SIZE = (IMAGE_CHANNELS, IMAGE_SIZE, IMAGE_SIZE) # (C, H, W)

## Define key hyperparameters for model training and inference
BATCH_SIZE = 32
EPOCHS     = 500
LR         = 1e-4
NUM_TRAIN_TIMESTEPS = 100
NUM_INFER_STEPS     = 25

if torch.cuda.is_available():
    DEVICE = 'cuda:0'
elif torch.backends.mps.is_available():
    DEVICE = 'mps'
else:
    DEVICE = 'cpu'

TRAINING_NUM_WORKERS = 8
PREPROCESS_NUM_WORKERS = 8
INFERENCE_NUM_WORKERS = 8

INFERENCE_BATCH_SIZE = 32
MODEL_PATH="weights/conditional_unet_checkpoint.pth" # Path to model weights for inference

LOSS_TYPE = "simple" # atm simple only
MODEL_DIM = "2D"
SPLITS_DIR = "splits"	

